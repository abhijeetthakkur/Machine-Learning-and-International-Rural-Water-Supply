{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "import csv\n",
    "import os\n",
    "path = 'Test1'\n",
    "with open('images2.csv') as csvDataFile:\n",
    "    csvReader = csv.reader(csvDataFile)\n",
    "    i=0\n",
    "    for row in csvReader:\n",
    "        if i==0:\n",
    "            i=2\n",
    "            continue\n",
    "        filename=row[0]\n",
    "        filepath=os.path.join(path,filename)\n",
    "        all_files=os.listdir(filepath)\n",
    "        for x in all_files:\n",
    "            newfilename=x.split(\".\")[0]+\"_\"+row[1]+\"_\"+row[2]+\".\"+x.split(\".\")[1]\n",
    "            newfilename_path=os.path.join(filepath,newfilename)\n",
    "            oldfilename_path=os.path.join(filepath,x)\n",
    "            os.rename(oldfilename_path,newfilename_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "\n",
    "X_data = []\n",
    "dir_files =\"Test1/imgaes/\"\n",
    "for img in os.listdir(dir_files):\n",
    "        img_array = cv2.imread(os.path.join(dir_files,img), cv2.IMREAD_GRAYSCALE)\n",
    "        resized_image = cv2.resize(img_array, (28, 28))\n",
    "#         img_flatten = resized_image.reshape(-1)\n",
    "        X_data.append(resized_image)\n",
    "np_X_data = np.array(X_data)        \n",
    "        \n",
    "print(np_X_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os, sys\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "Y_data = []\n",
    "#root_dir = \"Dissertation/list_of_images/\"\n",
    "#for ii in glob.iglob(root_dir + '**/*.jpg', recursive=True):\n",
    "dir_files = glob.glob(\"Test1/imgaes/**.JPG\")\n",
    "for ii in dir_files:\n",
    "# #     print(ii)\n",
    "#     im = Image.open(ii)\n",
    "#     imResize = im.resize((28,28), Image.ANTIALIAS)\n",
    "#     aaa=np.array(imResize)\n",
    "#     X_data.append(aaa)\n",
    "    if ii.find('_Not Corroded_Not Damaged')!=-1:\n",
    "        Y_data.append(2)\n",
    "    elif ii.find('_Not Corroded_Damaged')!=-1:\n",
    "        Y_data.append(1)\n",
    "    elif ii.find('_Corroded_Not Damaged')!=-1:\n",
    "        Y_data.append(3)\n",
    "    elif ii.find('_Corroded_Damaged')!=-1:\n",
    "        Y_data.append(0)\n",
    "\n",
    "np_Y_data = np.array(Y_data) \n",
    "# print(len(X_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    }
   ],
   "source": [
    "print(len(np_Y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(np_X_data[0,:,:].shape)\n",
    "# print(np_X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = 1 # how much data of each class\n",
    "c1, c2, c3= 2, 1, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of training subset: (3, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "index_of_c1 = np.argwhere(np_Y_data == c1).ravel() # index of 2s\n",
    "index_of_c1 = np.random.choice(index_of_c1, replace=False)\n",
    "\n",
    "index_of_c2 = np.argwhere(np_Y_data == c2).ravel() # index of 3s\n",
    "index_of_c2 = np.random.choice(index_of_c2, replace=False)\n",
    "\n",
    "index_of_c3 = np.argwhere(np_Y_data == c3).ravel() # index of 4s\n",
    "index_of_c3 = np.random.choice(index_of_c3, replace=False)\n",
    "\n",
    "# index_of_c4 = np.argwhere(np_Y_data == c4).ravel() # index of 4s\n",
    "# index_of_c4 = np.random.choice(index_of_c4, N, replace=False)\n",
    "\n",
    "x_train = np_X_data[np.hstack((index_of_c1, index_of_c2, index_of_c3))] # subsample\n",
    "y_train = np_Y_data[np.hstack((index_of_c1, index_of_c2, index_of_c3))] # subsample\n",
    "\n",
    "print(\"size of training subset: %s\" % str(x_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "as_rgb = lambda im: np.tile(np.expand_dims(im,2),(1,1,3))\n",
    "\n",
    "#example\n",
    "print(as_rgb(x_train[0,:,:]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38, 299, 299, 3)\n"
     ]
    }
   ],
   "source": [
    "import skimage\n",
    "resize = lambda im: skimage.transform.resize(as_rgb(im), (299, 299), preserve_range=False, order=0)\n",
    "\n",
    "new_x_train = np.concatenate([[resize(np_X_data[i,:,:])] for i in range(np_X_data.shape[0])])\n",
    "print(new_x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception = InceptionV3(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    pooling='avg',\n",
    "    input_shape=(299,299,3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38, 2048)\n"
     ]
    }
   ],
   "source": [
    "training_features = inception.predict(new_x_train)\n",
    "print(training_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC as Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Classifier()\n",
    "\n",
    "clf.fit(training_features, np_Y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = clf.predict(training_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 1.000000\n",
      "successfully classified: 38/38\n"
     ]
    }
   ],
   "source": [
    "acc = clf.score(training_features, np_Y_data)\n",
    "print(\"accuracy: %f\" % acc)\n",
    "print(\"successfully classified: %d/%d\" % (np.sum(y_predict == np_Y_data), len(np_Y_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "classifiers = {\n",
    "    'svm': SVC, \n",
    "    'sgd': SGDClassifier, \n",
    "    'linearsvm': LinearSVC,\n",
    "    'decisiontree': DecisionTreeClassifier,\n",
    "    'naivebayes': GaussianNB\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifer: svm\n",
      "  training accuracy: 0.421053\n",
      "  test accuracy: 0.421053\n",
      "classifer: sgd\n",
      "  training accuracy: 1.000000\n",
      "  test accuracy: 1.000000\n",
      "classifer: linearsvm\n",
      "  training accuracy: 1.000000\n",
      "  test accuracy: 1.000000\n",
      "classifer: decisiontree\n",
      "  training accuracy: 1.000000\n",
      "  test accuracy: 1.000000\n",
      "classifer: naivebayes\n",
      "  training accuracy: 1.000000\n",
      "  test accuracy: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "for name, Classifer in classifiers.items():\n",
    "    clf = Classifer()\n",
    "    clf.fit(training_features, np_Y_data)\n",
    "    train_acc = clf.score(training_features, np_Y_data)\n",
    "    test_acc  = clf.score(training_features,  np_Y_data)\n",
    "    print(\"classifer: %s\\n  training accuracy: %f\\n  test accuracy: %f\" % (name, train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
